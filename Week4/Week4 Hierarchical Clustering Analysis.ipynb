{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Hierarchical Clustering Analysis\n",
    "\n",
    "This notebook performs hierarchical clustering analysis on public utility data and spider abundance data.\n",
    "\n",
    "Hierarchical clustering is a technique for identifying groups or clusters in multivariate datasets. We do not need to pre-specify the number of clusters beforehand in order to peform the analysis, unlike say, k-means clustering (not part of the unit). A great feature of hierarchical clustering is that the sequence of groupings of observation or features is represented in a tree-based diagram, called dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster, cophenet\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.stats import spearmanr\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load and Prepare Data\n",
    "\n",
    "We begin with the public utility data of 22 U.S. power companies, which are given in the Public Utility.csv file. The relevant features are as follows:\n",
    "1.\tFixed charge coverage ratio (income/debt)\n",
    "2.\tRate of return on capital\n",
    "3.\tCost per KW capacity in place\n",
    "4.\tAnnual load factor\n",
    "5.\tPeak KWH demand growth\n",
    "6.\tSales (KWH use per year)\n",
    "7.\tPercent nuclear\n",
    "8.\tTotal fuel cost (cents per KWH)\n",
    "Given that the features are defined in different units, we should standardise the data before we create the distance matrix for hierarchical clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the public utility data\n",
    "url = \"https://raw.githubusercontent.com/asim-cv/MAT6206/refs/heads/main/Datasets/PublicUtility.csv\"\n",
    "dat = pd.read_csv(url)\n",
    "\n",
    "#dat = pd.read_csv(\"Public Utility.csv\")\n",
    "\n",
    "# Set company names as index and remove the Company column\n",
    "dat.set_index(dat.iloc[:, -1], inplace=True)\n",
    "dat = dat.iloc[:, :-1]\n",
    "\n",
    "print(\"Data shape:\", dat.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(dat.head())\n",
    "\n",
    "\n",
    "# Remove missing values and standardize\n",
    "dat = dat.dropna()\n",
    "scaler = StandardScaler()\n",
    "dat_z = pd.DataFrame(scaler.fit_transform(dat), \n",
    "                     index=dat.index, \n",
    "                     columns=dat.columns)\n",
    "\n",
    "print(\"\\nStandardized data shape:\", dat_z.shape)\n",
    "dat_z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Distance Matrix and Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance matrix heatmap with clustering\n",
    "dist_pu = pdist(dat_z, metric='euclidean')\n",
    "linkage_matrix = linkage(dist_pu, method='average')\n",
    "optimal_order = dendrogram(linkage_matrix, no_plot=True)['leaves']\n",
    "\n",
    "# Reorder and create heatmap\n",
    "reordered_companies = [dat_z.index[i] for i in optimal_order]\n",
    "dist_matrix = squareform(dist_pu)[np.ix_(optimal_order, optimal_order)]\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(dist_matrix, \n",
    "            cmap='RdYlBu_r',\n",
    "            xticklabels=reordered_companies,\n",
    "            yticklabels=reordered_companies,\n",
    "            square=True,\n",
    "            cbar_kws={'label': 'Distance'})\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Agglomerative Hierarchical Clustering (AGNES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "dendrogram(linkage_matrix,\n",
    "           labels=dat_z.index,\n",
    "           leaf_rotation=45,\n",
    "           leaf_font_size=10,\n",
    "           color_threshold=linkage_matrix[-4, 2]) # Set threshold to get 5 clusters\n",
    "\n",
    "plt.title('Hierarchical Clustering Dendrogram - 5 Clusters', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Companies', fontsize=12)\n",
    "plt.ylabel('Distance', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 DIANA Style Divisive Hierarchical Clustering Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Since there's no direct DIANA in scipy, we'll use divisive interpretation\n",
    "# of agglomerative results\n",
    "linkage_matrix_DIANA = linkage(dat_z, method='ward', metric='euclidean')\n",
    "\n",
    "# Plot dendrogram from divisive perspective (reading top-down)\n",
    "plt.figure(figsize=(16, 10))\n",
    "dendrogram(linkage_matrix_DIANA,\n",
    "           labels=dat_z.index,\n",
    "           leaf_rotation=45,\n",
    "           leaf_font_size=10,\n",
    "           orientation='top',\n",
    "           color_threshold=linkage_matrix_DIANA[-4, 2])  # For 5 clusters\n",
    "\n",
    "plt.title('DIANA-style Divisive Hierarchical Clustering Dendrogram', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Companies', fontsize=12)\n",
    "plt.ylabel('Distance', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Comparison of DIANA vs AGNES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisive Hierarchical Clustering (DIANA) - Alternative Implementation\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster, cophenet\n",
    "\n",
    "# Create divisive-like clustering using different linkage methods\n",
    "print(\"Divisive Hierarchical Clustering Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Use complete linkage (more divisive-like behavior)\n",
    "linkage_complete = linkage(dat_z, method='complete', metric='euclidean')\n",
    "linkage_ward = linkage(dat_z, method='ward')\n",
    "\n",
    "print(\"Comparing different linkage methods:\")\n",
    "print(f\"Complete linkage cophenetic correlation: {cophenet(linkage_complete, pdist(dat_z))[0]:.4f}\")\n",
    "print(f\"Ward linkage cophenetic correlation: {cophenet(linkage_ward, pdist(dat_z))[0]:.4f}\")\n",
    "print(f\"Average linkage cophenetic correlation: {cophenet(linkage_matrix, pdist(dat_z))[0]:.4f}\")\n",
    "print()\n",
    "\n",
    "# Plot dendrograms for different linkage methods\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Complete linkage dendrogram\n",
    "dendrogram(linkage_complete, \n",
    "           labels=dat_z.index,\n",
    "           leaf_rotation=45,\n",
    "           leaf_font_size=8,\n",
    "           color_threshold=linkage_complete[-4, 2],\n",
    "           ax=ax1)\n",
    "ax1.set_title('Complete Linkage Dendrogram (More Divisive-like)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Companies')\n",
    "ax1.set_ylabel('Distance')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Ward linkage dendrogram\n",
    "dendrogram(linkage_ward, \n",
    "           labels=dat_z.index,\n",
    "           leaf_rotation=45,\n",
    "           leaf_font_size=8,\n",
    "           color_threshold=linkage_ward[-4, 2],\n",
    "           ax=ax2)\n",
    "ax2.set_title('Ward Linkage Dendrogram (Divisive-like)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Companies')\n",
    "ax2.set_ylabel('Distance')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compare cluster assignments\n",
    "clusters_complete = fcluster(linkage_complete, 5, criterion='maxclust')\n",
    "clusters_ward = fcluster(linkage_ward, 5, criterion='maxclust')\n",
    "\n",
    "print(\"Cluster comparison:\")\n",
    "print(f\"Complete linkage creates {len(set(clusters_complete))} clusters\")\n",
    "print(f\"Ward linkage creates {len(set(clusters_ward))} clusters\")\n",
    "print(f\"Average linkage creates {len(set(fcluster(linkage_matrix, 5, criterion='maxclust')))} clusters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 PCA Plot with clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Plot with Cluster Shapes and Separate Legend Shapes\n",
    "k = 5\n",
    "clusters = fcluster(linkage_matrix, k, criterion='maxclust')\n",
    "\n",
    "# PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "dat_pca = pca.fit_transform(dat_z)\n",
    "\n",
    "# Create scatter plot with cluster shapes and separate legend shapes\n",
    "plt.figure(figsize=(14, 12))\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, k))\n",
    "\n",
    "# Define different marker shapes for each cluster\n",
    "markers = ['o', 's', '^', 'D', 'v']  # circle, square, triangle up, diamond, triangle down\n",
    "\n",
    "for i in range(k):\n",
    "    mask = clusters == (i + 1)\n",
    "    cluster_points = dat_pca[mask]\n",
    "    \n",
    "    # Draw convex hull shape around cluster\n",
    "    if len(cluster_points) >= 3:\n",
    "        hull = ConvexHull(cluster_points)\n",
    "        # Fill the hull with soft color\n",
    "        hull_points = cluster_points[hull.vertices]\n",
    "        plt.fill(hull_points[:, 0], hull_points[:, 1], \n",
    "                color=colors[i], alpha=0.2)\n",
    "        # Draw hull border\n",
    "        for simplex in hull.simplices:\n",
    "            plt.plot(cluster_points[simplex, 0], cluster_points[simplex, 1], \n",
    "                    color=colors[i], linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Plot points with different shapes\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                c=[colors[i]], marker=markers[i], s=100, alpha=0.8, \n",
    "                edgecolors='white', linewidth=1, label=f'Cluster {i+1}')\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)', fontsize=12)\n",
    "plt.title('PCA Plot with Cluster Shapes and Separate Legend Shapes', fontsize=14, fontweight='bold')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cophenetic correlation\n",
    "coph_cor, coph_dist = cophenet(linkage_matrix, dist_pu)\n",
    "print(f\"Cophenetic correlation: {coph_cor:.4f}\")\n",
    "\n",
    "# Calculate silhouette score\n",
    "silhouette_avg = silhouette_score(dat_z, clusters)\n",
    "print(f\"Average silhouette score: {silhouette_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal number of clusters analysis (fixed version without yellowbrick)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Elbow Method - Calculate inertia for different numbers of clusters\n",
    "k_range = range(2, 16)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    clustering = AgglomerativeClustering(n_clusters=k, linkage='average')\n",
    "    cluster_labels = clustering.fit_predict(dat_z)\n",
    "    \n",
    "    # Calculate inertia (within-cluster sum of squares)\n",
    "    inertia = 0\n",
    "    for i in range(k):\n",
    "        cluster_points = dat_z[cluster_labels == i]\n",
    "        if len(cluster_points) > 0:\n",
    "            centroid = cluster_points.mean()\n",
    "            inertia += ((cluster_points - centroid) ** 2).sum().sum()\n",
    "    \n",
    "    inertias.append(inertia)\n",
    "    silhouette_scores.append(silhouette_score(dat_z, cluster_labels))\n",
    "\n",
    "# Plot Elbow Method\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia (Within-cluster Sum of Squares)')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(k_range)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Method for Optimal Number of Clusters')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(k_range)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print results for k=5\n",
    "k = 5\n",
    "clustering = AgglomerativeClustering(n_clusters=k, linkage='average')\n",
    "cluster_labels = clustering.fit_predict(dat_z)\n",
    "inertia = inertias[k-2]  # k=5 is at index 3 (k_range starts at 2)\n",
    "sil_score = silhouette_scores[k-2]\n",
    "\n",
    "print(f\"Results for k = {k} clusters:\")\n",
    "print(f\"- Inertia: {inertia:.4f}\")\n",
    "print(f\"- Silhouette Score: {sil_score:.4f}\")\n",
    "print(f\"- Optimal k (Elbow): {k_range[np.argmin(np.diff(inertias)) + 1]}\")\n",
    "print(f\"- Optimal k (Silhouette): {k_range[np.argmax(silhouette_scores)]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Variable Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose data for variable clustering\n",
    "dat_z_trp = dat_z.T\n",
    "\n",
    "# Create distance matrix for variables\n",
    "dist_pu_trp = pdist(dat_z_trp, metric='euclidean')\n",
    "dist_matrix_trp = squareform(dist_pu_trp)\n",
    "\n",
    "# Perform clustering on variables\n",
    "linkage_matrix_trp = linkage(dat_z_trp, method='average', metric='euclidean')\n",
    "\n",
    "# Plot dendrogram for variables\n",
    "plt.figure(figsize=(12, 8))\n",
    "dendrogram(linkage_matrix_trp, \n",
    "          labels=dat_z_trp.index,\n",
    "          leaf_rotation=90,\n",
    "          leaf_font_size=10)\n",
    "plt.title('Variable Clustering Dendrogram (Average Linkage)')\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Distance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate cophenetic correlation for variables\n",
    "coph_cor_trp, _ = cophenet(linkage_matrix_trp, dist_pu_trp)\n",
    "print(f\"Variable clustering cophenetic correlation: {coph_cor_trp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 Heatmap with Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have performed AGNES on both the samples and the features, we can now combined the two results, together with a distance matrix heatmap, to better understand the relationship between the U.S. utility companies and their operations as it related to the measured features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap with clustering\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create custom colormap\n",
    "colors = ['gray', 'white', 'red']\n",
    "n_bins = 15\n",
    "cmap = sns.blend_palette(colors, n_colors=n_bins, as_cmap=True)\n",
    "\n",
    "# Create heatmap\n",
    "g = sns.clustermap(dat_z, \n",
    "                   cmap=cmap,\n",
    "                   row_linkage=linkage_matrix,\n",
    "                   col_linkage=linkage_matrix_trp,\n",
    "                   xticklabels=True,\n",
    "                   yticklabels=True,\n",
    "                   figsize=(12, 10))\n",
    "\n",
    "plt.title('Clustered Heatmap of Standardized Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 Spider Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/asim-cv/MAT6206/refs/heads/main/Datasets/Spider.csv\"\n",
    "spider_df = pd.read_csv(url)\n",
    "\n",
    "display(spider_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering of sites using Bray-Curtis distance - Modified to show 4 clusters\n",
    "from scipy.spatial.distance import braycurtis\n",
    "\n",
    "dist_site = pdist(spider_df, metric=braycurtis)\n",
    "linkage_site = linkage(spider_df, method='average', metric=braycurtis)\n",
    "\n",
    "# Plot dendrogram for sites showing 4 clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "dendrogram(linkage_site, \n",
    "          labels=spider_df.index,\n",
    "          leaf_rotation=90,\n",
    "          leaf_font_size=8,\n",
    "          color_threshold=linkage_site[-3, 2])  # Set threshold to show 4 clusters\n",
    "plt.title('Site Clustering Dendrogram (Bray-Curtis Distance) - 4 Clusters')\n",
    "plt.xlabel('Sites')\n",
    "plt.ylabel('Distance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate cophenetic correlation for sites\n",
    "coph_cor_site, _ = cophenet(linkage_site, dist_site)\n",
    "print(f\"Site clustering cophenetic correlation: {coph_cor_site:.4f}\")\n",
    "\n",
    "# Show cluster assignments for 4 clusters\n",
    "clusters_site = fcluster(linkage_site, 4, criterion='maxclust')\n",
    "print(f\"\\nCluster assignments for 4 clusters:\")\n",
    "for i in range(4):\n",
    "    cluster_sites = spider_df.index[clusters_site == (i + 1)]\n",
    "    print(f\"Cluster {i+1}: {list(cluster_sites)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering of species\n",
    "dist_species = pdist(spider_df.T, metric=braycurtis)\n",
    "linkage_species = linkage(spider_df.T, method='average', metric=braycurtis)\n",
    "\n",
    "# Plot dendrogram for species\n",
    "plt.figure(figsize=(12, 8))\n",
    "dendrogram(linkage_species, \n",
    "          labels=spider_df.columns,\n",
    "          leaf_rotation=90,\n",
    "          leaf_font_size=8,\n",
    "          color_threshold=linkage_species[-4, 2])\n",
    "plt.title('Species Clustering Dendrogram (Bray-Curtis Distance) - 5 Clusters')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Distance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate cophenetic correlation for species\n",
    "coph_cor_species, _ = cophenet(linkage_species, dist_species)\n",
    "print(f\"Species clustering cophenetic correlation: {coph_cor_species:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap for spider data\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "g = sns.clustermap(spider_df, \n",
    "                   cmap='viridis',\n",
    "                   row_linkage=linkage_site,\n",
    "                   col_linkage=linkage_species,\n",
    "                   xticklabels=True,\n",
    "                   yticklabels=True,\n",
    "                   figsize=(12, 10))\n",
    "\n",
    "plt.title('Clustered Heatmap of Spider Abundance Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the obvious with Pardnigr, Pardpull, Trocterr and Pardmont and the corresponding sites, it is difficult to make any sensible observation with the other species/sites. This is largely due to the fact the few large counts (as seen by the red cells in the above plot) that are >80 are drowning out the smaller counts (around 10 or less), and the latter make up the majority of the cases (see legend key). A way to overcome this is by transforming the whole dataset using, say the fourth-root transformation. A transformation reducing the distances between the low and high counts, and as a result, the lower values are given more emphasis. In biology, rare species are often times just as important as the common species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth root transformation\n",
    "dat_abund_4root = spider_df ** (1/4)\n",
    "\n",
    "# AGNES by sites on transformed data\n",
    "dist_site_4root = pdist(dat_abund_4root, metric=braycurtis)\n",
    "linkage_site_4root = linkage(dat_abund_4root, method='average', metric=braycurtis)\n",
    "\n",
    "# AGNES by species on transformed data\n",
    "dist_species_4root = pdist(dat_abund_4root.T, metric=braycurtis)\n",
    "linkage_species_4root = linkage(dat_abund_4root.T, method='average', metric=braycurtis)\n",
    "\n",
    "# Create heatmap for transformed data\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "g = sns.clustermap(dat_abund_4root, \n",
    "                   cmap='viridis',\n",
    "                   row_linkage=linkage_site_4root,\n",
    "                   col_linkage=linkage_species_4root,\n",
    "                   xticklabels=True,\n",
    "                   yticklabels=True,\n",
    "                   figsize=(12, 10))\n",
    "\n",
    "plt.title('Clustered Heatmap of Fourth Root Transformed Spider Data')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
