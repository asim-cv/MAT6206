{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 PCA and PCoA Analysis in Python\n",
    "\n",
    "This notebook demonstrates Principal Component Analysis (PCA) and Principal Coordinate Analysis (PCoA) using Python.\n",
    "\n",
    "PCA is an unsupervised technique that takes high dimensional data and represent them in lower dimension by exploiting the relationships between the variables, without too much loss of information. PCA is the most popular dimension reduction technique. It also serves as an intermediate step to other analyses such as factor analysis and principal component regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.spatial.distance import cdist\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "\n",
    "# Define a single consistent species palette and colors mapping\n",
    "aesthetic_palette = ['#1f77b4', '#ff7f0e', '#2ca02c']  # blue, orange, green\n",
    "species_order = ['setosa', 'versicolor', 'virginica']\n",
    "species_palette = dict(zip(species_order, aesthetic_palette))\n",
    "\n",
    "# Apply palette to seaborn globally\n",
    "sns.set_palette(aesthetic_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load and Prepare Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "url = \"https://raw.githubusercontent.com/asim-cv/MAT6206/refs/heads/main/Datasets/iris.csv\"\n",
    "iris_df = pd.read_csv(url)\n",
    "\n",
    "display(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Scatter Plot Matrix\n",
    "\n",
    "Create a scatter plot matrix showing the bivariate relationships between the four features of the iris flowers. The diagonal plots are empty (showing only feature names) and the off-diagonal plots show scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PairGrid without the upper triangle\n",
    "# Ensure consistent hue order and palette\n",
    "g = sns.PairGrid(\n",
    "    iris_df,\n",
    "    hue='species',\n",
    "    corner=False,\n",
    "    hue_order=species_order,\n",
    "    palette=species_palette\n",
    ")\n",
    "\n",
    "# Map scatter plots to the lower triangle\n",
    "g.map_lower(sns.scatterplot)\n",
    "\n",
    "# Map KDE plots to the diagonal\n",
    "g.map_diag(sns.kdeplot, fill=True)\n",
    "\n",
    "# Turn off upper triangle\n",
    "for i, j in zip(*np.triu_indices_from(g.axes, 1)):\n",
    "    g.axes[i, j].set_visible(False)\n",
    "\n",
    "# Add legend\n",
    "g.add_legend(title='Species')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_features = iris_df.iloc[:, 0:4].values  # assumes first 4 columns are features\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "iris_features_scaled = scaler.fit_transform(iris_features)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "pca_iris = pca.fit_transform(iris_features_scaled)\n",
    "\n",
    "\n",
    "# Get explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Create a DataFrame for better display\n",
    "variance_df = pd.DataFrame({\n",
    "    'Principal Component': [f'PC{i+1}' for i in range(len(explained_variance))],\n",
    "    'Explained Variance Ratio': explained_variance,\n",
    "    'Cumulative Variance': cumulative_variance\n",
    "})\n",
    "\n",
    "# Display the variance explained\n",
    "display(variance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 PCA Summary and Variance Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show variance explained\n",
    "print(\"Explained variance ratio:\")\n",
    "for i, var in enumerate(pca.explained_variance_ratio_):\n",
    "    print(f\"PC{i+1}: {var:.4f} ({var*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nCumulative explained variance:\")\n",
    "cumulative_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "for i, var in enumerate(cumulative_var):\n",
    "    print(f\"PC{i+1}: {var:.4f} ({var*100:.1f}%)\")\n",
    "\n",
    "# Show loadings (rotation matrix)\n",
    "print(\"\\nPCA Loadings (Rotation Matrix):\")\n",
    "loadings_df = pd.DataFrame(pca.components_.T, \n",
    "                          columns=[f'PC{i+1}' for i in range(pca.n_components_)],\n",
    "                          index=iris_df.columns[:4])\n",
    "print(loadings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Scree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scree plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "         pca.explained_variance_ratio_, 'bo-', linewidth=2, markersize=8)\n",
    "plt.title('Scree Plot - Iris Dataset', fontsize=14)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add percentage labels\n",
    "for i, var in enumerate(pca.explained_variance_ratio_):\n",
    "    plt.annotate(f'{var*100:.1f}%', \n",
    "                 xy=(i+1, var), \n",
    "                 xytext=(0, 10), \n",
    "                 textcoords='offset points', \n",
    "                 ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Code to draw eclipses on the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "def draw_confidence_ellipse(ax, x, y, color, level=0.95, lw=2, alpha=0.15):\n",
    "    pts = np.column_stack((x, y))\n",
    "    if pts.shape[0] < 3:\n",
    "        return\n",
    "    cov = np.cov(pts, rowvar=False)\n",
    "    vals, vecs = np.linalg.eigh(cov)\n",
    "    order = vals.argsort()[::-1]\n",
    "    vals, vecs = vals[order], vecs[:, order]\n",
    "    angle = np.degrees(np.arctan2(*vecs[:, 0][::-1]))\n",
    "    chi2_val = chi2.ppf(level, df=2)\n",
    "    width, height = 2 * np.sqrt(np.maximum(vals, 1e-12) * chi2_val)\n",
    "    mean = pts.mean(axis=0)\n",
    "    e = Ellipse(\n",
    "        xy=mean,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        angle=angle,\n",
    "        edgecolor=color,\n",
    "        facecolor=color,\n",
    "        lw=lw,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    ax.add_patch(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Visulize the first two dimensions, i.e. PC1 and PC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load data and PCA as before\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "species = pd.Categorical.from_codes(y, iris.target_names)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_scores = pca.fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(pca_scores, columns=['PC1', 'PC2'])\n",
    "pca_df['Species'] = species\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='PC1', y='PC2', hue='Species', s=100, alpha=0.8,\n",
    "    hue_order=species_order, palette=species_palette\n",
    ")\n",
    "\n",
    "# Overlay 95% confidence ellipses per species\n",
    "ax = plt.gca()\n",
    "for sp in species_order:\n",
    "    m = pca_df['Species'] == sp\n",
    "    draw_confidence_ellipse(ax, pca_df.loc[m, 'PC1'], pca_df.loc[m, 'PC2'], species_palette[sp]) # Draw the eclipse on the plot\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA of Iris Dataset')\n",
    "\n",
    "# Adjust legend - move it slightly above the plot and add spacing with top\n",
    "plt.legend(title='Species', loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=3)\n",
    "\n",
    "# Increase top margin to prevent overlap between title and legend\n",
    "plt.subplots_adjust(top=0.8)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 3D PCA Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Required for 3D plotting\n",
    "\n",
    "# Create 3D PCA results using existing scaled data\n",
    "# The existing pca object already has all components, we just need to extract the first 3\n",
    "pca_3d_scores = pca_iris[:, :3]  # Take first 3 components from existing pca_iris\n",
    "\n",
    "# Create DataFrame with 3D PCA results using existing iris_df\n",
    "pca_df_3d = pd.DataFrame(pca_3d_scores, columns=['PC1', 'PC2', 'PC3'])\n",
    "pca_df_3d['Species'] = iris_df['species']  # Use species column from existing iris_df\n",
    "\n",
    "# Use the global species_palette for consistent colors\n",
    "\n",
    "# Check column names and unique species in your DataFrame\n",
    "print(\"Columns in pca_df_3d:\", pca_df_3d.columns)\n",
    "print(\"Unique species values:\", pca_df_3d['Species'].unique())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for species_name in species_order:\n",
    "    mask = pca_df_3d['Species'] == species_name\n",
    "    # Debug print count of points for each species\n",
    "    print(f\"Species: {species_name}, Points: {mask.sum()}\")\n",
    "    \n",
    "    if mask.sum() == 0:\n",
    "        print(f\"Warning: No data found for species '{species_name}'\")\n",
    "        continue\n",
    "    \n",
    "    ax.scatter(\n",
    "        pca_df_3d.loc[mask, 'PC1'],\n",
    "        pca_df_3d.loc[mask, 'PC2'],\n",
    "        pca_df_3d.loc[mask, 'PC3'],\n",
    "        c=species_palette[species_name],\n",
    "        label=species_name,\n",
    "        alpha=0.7,\n",
    "        s=60\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('PC1', fontsize=12)\n",
    "ax.set_ylabel('PC2', fontsize=12)\n",
    "ax.set_zlabel('PC3', fontsize=12)\n",
    "ax.set_title('3D PCA Plot - Iris Dataset', fontsize=16)\n",
    "ax.legend(title='Species')\n",
    "\n",
    "# Set the viewing angle: e.g. elev=30°, azim=45°\n",
    "ax.view_init(elev=30, azim=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 PCA Biplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load dataset\n",
    "df = iris_df\n",
    "X = df.iloc[:, :4]\n",
    "y = df['species']  # for coloring\n",
    "\n",
    "# Standardize\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Get loadings\n",
    "loadings = pca.components_.T\n",
    "features = X.columns\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Scatter plot of PCA scores, color by species using global palette\n",
    "for sp in species_order:\n",
    "    idx = y == sp\n",
    "    plt.scatter(X_pca[idx, 0], X_pca[idx, 1], label=sp, color=species_palette[sp])\n",
    "\n",
    "# Overlay 95% confidence ellipses\n",
    "ax = plt.gca()\n",
    "for sp in species_order:\n",
    "    idx = y == sp\n",
    "    draw_confidence_ellipse(ax, X_pca[idx, 0], X_pca[idx, 1], species_palette[sp])\n",
    "\n",
    "# Plot the vectors (loadings)\n",
    "for i, feature in enumerate(features):\n",
    "    plt.arrow(0, 0, \n",
    "              loadings[i, 0]*3,  # scale for visibility\n",
    "              loadings[i, 1]*3, \n",
    "              color='black', alpha=0.5, head_width=0.1)\n",
    "    plt.text(loadings[i, 0]*3.2, \n",
    "             loadings[i, 1]*3.2, \n",
    "             feature, color='black', ha='center', va='center')\n",
    "\n",
    "# Axis labels with variance explained\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "plt.title('PCA Biplot')\n",
    "plt.grid(True)\n",
    "plt.axhline(0, color='grey', lw=1)\n",
    "plt.axvline(0, color='grey', lw=1)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Principal Coordinate Analysis (PCoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCoA on Iris dataset using Euclidean distance\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "# Use the existing iris features (already standardized from earlier cells)\n",
    "# iris_features_scaled is available from the main PCA analysis\n",
    "\n",
    "# Calculate Euclidean distance matrix\n",
    "distances_iris = pdist(iris_features_scaled, metric='euclidean')\n",
    "dist_matrix_iris = squareform(distances_iris)\n",
    "\n",
    "# Perform PCoA (MDS with metric=True) using Euclidean distance\n",
    "mds_iris = MDS(n_components=3, metric=True, random_state=42, dissimilarity='precomputed')\n",
    "pcoa_iris = mds_iris.fit_transform(dist_matrix_iris)\n",
    "\n",
    "# Create DataFrame for PCoA results\n",
    "pcoa_iris_df = pd.DataFrame(pcoa_iris, columns=['Dim1', 'Dim2', 'Dim3'])\n",
    "pcoa_iris_df['Species'] = iris_df['species']\n",
    "\n",
    "# Calculate proportion of variance explained by first two dimensions\n",
    "total_variance_iris = np.sum(pcoa_iris**2, axis=0)\n",
    "variance_explained_iris = total_variance_iris / np.sum(total_variance_iris)\n",
    "print(f\"Proportion of variance explained by 1st two dimensions (Iris PCoA):\")\n",
    "print(f\"Dim1: {variance_explained_iris[0]:.4f}\")\n",
    "print(f\"Dim2: {variance_explained_iris[1]:.4f}\")\n",
    "\n",
    "# Plot PCoA results\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for species_name in species_order:\n",
    "    mask = pcoa_iris_df['Species'] == species_name\n",
    "    ax.scatter(\n",
    "        pcoa_iris_df.loc[mask, 'Dim1'], \n",
    "        pcoa_iris_df.loc[mask, 'Dim2'], \n",
    "        c=species_palette[species_name], \n",
    "        label=species_name, \n",
    "        alpha=0.7, \n",
    "        s=60\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('PCO1')\n",
    "ax.set_ylabel('PCO2')\n",
    "ax.set_title('PCoA of Iris Dataset (Euclidean Distance)')\n",
    "ax.legend(title='Species')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCoA completed! Stress: {mds_iris.stress_:.4f}\")\n",
    "print(f\"Number of samples: {len(pcoa_iris_df)}\")\n",
    "print(f\"Number of features: {len(iris_df.columns)-1}\")  # Exclude species column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer dataset\n",
    "bc_data = load_breast_cancer()\n",
    "bc_df = pd.DataFrame(bc_data.data, columns=bc_data.feature_names)\n",
    "bc_df['target'] = bc_data.target\n",
    "\n",
    "# Remove any missing values\n",
    "bc_df = bc_df.dropna()\n",
    "\n",
    "print(\"Breast Cancer dataset shape:\", bc_df.shape)\n",
    "print(\"Number of features:\", len(bc_data.feature_names))\n",
    "bc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11 Spider Dataset Simulation\n",
    "\n",
    "Since the spider dataset is not readily available in Python, we'll create a simulated version to demonstrate the concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simulated spider abundance data\n",
    "url = \"https://raw.githubusercontent.com/asim-cv/MAT6206/refs/heads/main/Datasets/Spider.csv\"\n",
    "spider_df = pd.read_csv(url)\n",
    "\n",
    "print(\"Spider Abundance Data:\")\n",
    "print(f\"Shape: {spider_df.shape}\")\n",
    "\n",
    "spider_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12 Spider PCoA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCoA on spider abundance data\n",
    "from scipy.spatial.distance import braycurtis\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "# Calculate Bray-Curtis distance matrix\n",
    "dist_spider = pdist(spider_df.values, metric=braycurtis)\n",
    "dist_matrix_spider = squareform(dist_spider)\n",
    "\n",
    "# Perform PCoA \n",
    "mds_spider = MDS(n_components=3, metric=True, random_state=42, dissimilarity='precomputed')\n",
    "pcoa_spider = mds_spider.fit_transform(dist_matrix_spider)\n",
    "\n",
    "# Calculate proportion of variance explained by first two dimensions\n",
    "total_variance = np.sum(pcoa_spider**2, axis=0)\n",
    "variance_explained = total_variance / np.sum(total_variance)\n",
    "print(f\"Proportion of variance explained by 1st two dimensions:\")\n",
    "print(f\"PCO1: {variance_explained[0]:.4f}\")\n",
    "print(f\"PCO2: {variance_explained[1]:.4f}\")\n",
    "\n",
    "# Plot the first two dimensions\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Create heat colors for 28 sites\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 28))\n",
    "\n",
    "# Plot points\n",
    "scatter = ax.scatter(pcoa_spider[:, 0], pcoa_spider[:, 1], \n",
    "                     c=colors, alpha=0.8, s=60)\n",
    "\n",
    "# Add site labels\n",
    "for i in range(28):\n",
    "    ax.annotate(f'S{i+1}', \n",
    "                (pcoa_spider[i, 0], pcoa_spider[i, 1] + 0.04),\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('PCO1')\n",
    "ax.set_ylabel('PCO2')\n",
    "ax.set_title('PCoA of Spider Sites (Bray-Curtis Distance)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove legend\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of sites: {len(spider_df)}\")\n",
    "print(f\"Number of species: {len(spider_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Bray-Curtis distance matrix for species (transpose of spider_df)\n",
    "dist_spider2 = pdist(spider_df.T.values, metric=braycurtis)\n",
    "dist_matrix_spider2 = squareform(dist_spider2)\n",
    "\n",
    "# Perform PCoA on species\n",
    "mds_spider2 = MDS(n_components=2, metric=True, random_state=42, dissimilarity='precomputed')\n",
    "pcoa_spider2 = mds_spider2.fit_transform(dist_matrix_spider2)\n",
    "\n",
    "# Calculate proportion of variance explained by first two dimensions\n",
    "total_variance2 = np.sum(pcoa_spider2**2, axis=0)\n",
    "variance_explained2 = total_variance2 / np.sum(total_variance2)\n",
    "print(f\"Proportion of variance explained by 1st two dimensions (Species):\")\n",
    "print(f\"PCO1: {variance_explained2[0]:.4f}\")\n",
    "print(f\"PCO2: {variance_explained2[1]:.4f}\")\n",
    "\n",
    "# Plot the first two dimensions\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Get species names \n",
    "species_names = spider_df.columns.tolist()\n",
    "\n",
    "# Plot points with different colors for each species\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(species_names)))\n",
    "scatter = ax.scatter(pcoa_spider2[:, 0], pcoa_spider2[:, 1], \n",
    "                     c=colors, alpha=0.8, s=60)\n",
    "\n",
    "# Add species labels \n",
    "for i, species in enumerate(species_names):\n",
    "    ax.annotate(species, \n",
    "                (pcoa_spider2[i, 0], pcoa_spider2[i, 1] + 0.035),\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('PCO1')\n",
    "ax.set_ylabel('PCO2')\n",
    "ax.set_title('PCoA of Spider Species (Bray-Curtis Distance)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove legend\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of species: {len(species_names)}\")\n",
    "print(f\"Species names: {species_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Principal Component Analysis (PCA)**: Dimensionality reduction technique that finds orthogonal directions of maximum variance\n",
    "2. **Principal Coordinate Analysis (PCoA)**: Similar to PCA but works with distance matrices\n",
    "3. **Visualization**: Various plots including scatter matrices, biplots, and 3D plots\n",
    "4. **Distance Metrics**: Euclidean distance for continuous data and Bray-Curtis for abundance data\n",
    "\n",
    "The analysis shows how these techniques can reveal patterns in high-dimensional data and help visualize relationships between samples and variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
